{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## SQL Translate"
      ],
      "metadata": {
        "id": "KuMB5xs8loWo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WduIsM2MmESY",
        "outputId": "15da31e0-910f-4636-9b55-c58bbfbbd3d1"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting openai\n",
            "  Downloading openai-0.27.7-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai) (2.27.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.65.0)\n",
            "Collecting aiohttp (from openai)\n",
            "  Downloading aiohttp-3.8.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m38.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.1.0)\n",
            "Collecting multidict<7.0,>=4.5 (from aiohttp->openai)\n",
            "  Downloading multidict-6.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3 (from aiohttp->openai)\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting yarl<2.0,>=1.0 (from aiohttp->openai)\n",
            "  Downloading yarl-1.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m27.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting frozenlist>=1.1.1 (from aiohttp->openai)\n",
            "  Downloading frozenlist-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (149 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiosignal>=1.1.2 (from aiohttp->openai)\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Installing collected packages: multidict, frozenlist, async-timeout, yarl, aiosignal, aiohttp, openai\n",
            "Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 frozenlist-1.3.3 multidict-6.0.4 openai-0.27.7 yarl-1.9.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "api_key = \"sk-...................................................Qa\"\n",
        "openai.api_key = api_key"
      ],
      "metadata": {
        "id": "8yn1eXe9mKCW"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"### Microsoft SQL tables, with their properties:\n",
        "#\n",
        "# Employee(id, name, department_id)\n",
        "# Department(id, name, address)\n",
        "# Sales_amount(id, employee_id, amount, date)\n",
        "#\n",
        "### A query to list the names of employees whose total sales in the last 3 months have been more than 10 thousand EURO\n",
        "SELECT\"\"\""
      ],
      "metadata": {
        "id": "cXZDa1FwTO2D"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "Ewezmz6P00gn",
        "outputId": "e92bb4b5-271f-49a7-94ca-4e6fee5c0ca7"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'### Microsoft SQL tables, with their properties:\\n#\\n# Employee(id, name, department_id)\\n# Department(id, name, address)\\n# Sales_amount(id, employee_id, amount, date)\\n#\\n### A query to list the names of employees whose total sales in the last 3 months have been more than 10 thousand EURO\\nSELECT'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "\n",
        "response = openai.Completion.create(\n",
        "  model=\"text-davinci-003\",\n",
        "  prompt=prompt,\n",
        "  temperature=0,\n",
        "  max_tokens=150,\n",
        "  top_p=1.0,\n",
        "  frequency_penalty=0.0,\n",
        "  presence_penalty=0.0,\n",
        "  stop=[\"#\", \";\"]\n",
        ")\n",
        "\n",
        "# GPT modellerinde temperature parametresi, çıktının rastgeleliğini/kalitesini kontrol eder. 0 ile 2 arasında ayarlanır, 0 en tahmin edilebilir/en kaliteli\n",
        "# ve 2 en rastgele/en kalitesiz çıktıyı döndürür. \n",
        "# Temperature 0 olduğunda, GPT her seferinde en yüksek olası yanıtı seçer. Temperature parametresi 2 olarak ayarlandığında, çıktının rastgeleliği artar ve çıktı kalitesi çok düşer.\n",
        "# Ancak temperature değeri MAX 0.8 ve civarı değerler tavsiye edilir.\n",
        "# temperature örnek:\n",
        "# \"\"Kahramanımız elindeki kılıcı ile ejderhayı .....\"\" cümlesinde takip eden kelimelerin/tokenlerin olasılıkları %40 öldürdü, %30 yendi, %20 yaraladı, %7 korkuttu, %3 öptü olsun.\n",
        "# temperature 0, 0.1 gibi çok düşük değerler olarak ayarlanırsa model takip eden kelime olarak en yüksek olasılıklı \"öldürdü\" kelimesini seçer.\n",
        "# temperature 0.2, 0.3 gibi düşük değerler ayarlanırsa model takip eden kelime olarak en yüksek olasılıklı \"öldürdü\", \"yendi\" kelimelerinden birini seçer. \n",
        "# temperature 2 civarı değerler seçilirse model takip eden kelime olarak en düşük olasılıklı kelimeler de dahil olmak üzere olası tüm kelimelerden herhangi birini seçer.\n",
        "\n",
        "\n",
        "# GPT modellerinde top_p parametresi, bir sonraki kelimenin model tarafından ne kadar çeşitli şekillerde tahmin edilebileceğini belirler. top_p=1.0 olduğunda model, \n",
        "# tüm olası kelimeleri seçebilir. top_p=0.5 olduğunda ise model, tüm olası kelimelerin ilk %50'lik kısmındaki kelimeleri seçebilir. \n",
        "# Büyük top_p (0.9 ve üzeri) değeri modelin daha fazla, küçük top_p (0.5 ve altı) değeri ise modelin daha az çeşitlilik göstermesine sağlar.\n",
        "# top_p örnek:\n",
        "# yukardaki örnek cümle için top_p 0.7 olarak ayarlanırsa takip eden kelimeyi, en yüksek olasılıktan başlayacak şekilde kümülatif toplamları 0.7'yi (0.4 öldürdü, 0.3 yendi) \n",
        "# geçmeyen kelimeler arasından seçer.\n",
        "\n",
        "# top_p 0.65 olarak ayarlanırsa takip eden kelimeyi, en yüksek olasılıktan başlayacak şekilde kümülatif toplamları 0.65'i (0.4 öldürdü) geçmeyen kelimeler arasından seçer. Çünkü\n",
        "# 0.4 olasılığa sahip \"öldürdü\" kelimesi ile 0.3 olasılığına sahip \"yendi\" kelimesinin kümülatif olasılık toplamı(0.7) 0.65'den büyük olduğundan sadece en büyük olasılığa sahip\n",
        "# \"öldürdü\" kelimesini seçer \"yendi\" kelimesini ignore eder. \n",
        "\n",
        "# top_p 0.26 olarak ayarlanırsa takip eden kelimeyi, en yüksek olasılıktan başlayacak şekilde kümülatif toplamları 0.26'yı (0.2 yaraladı) geçmeyen kelimeler arasından seçer. Çünkü\n",
        "# 0.2 olasılığa sahip \"yaraladı\" kelimesi ile 0.07 olasılığına sahip \"korkuttu\" kelimesinin kümülatif olasılık toplamı(0.27) 0.26'den büyük olduğundan sadece en büyük olasılığa sahip\n",
        "# \"yaraladı\" kelimesini seçer \"korkuttu\" kelimesini ignore eder.\n",
        "\n",
        "# hem top_p'nin 1 (max) hem de temperature'nin 2 (max) ayarlanması çıktının rassallığını çok fazla artıracağından alınan çıktının kalitesi çok kötü olacaktır. \n",
        "# DİKKAT, ÇOK ÖNEMLİ: 1. En olası çıktıyı elde etmek için top_p'nin her zaman 1, temperaturenin da 0 olarak ayarlanması, \n",
        "#                     2. Çıktının rassalığının artırılması istenirse top_p'nin 1'de sabit bırakılarak sadece temperature hyper_parametresi ile oynanması openai tarafından \n",
        "#                        tavsiye edilmiştir.\n",
        "\n",
        "#  positif değerler : “Frequency penalty”, bir kelimenin kullanım sayısı arttıkça o kelimenin tekrar seçilme olasılığını düşürürken, “presence penalty” bir kelimenin daha \n",
        "# önce kullanılmış olup olmadığına bakarak tekrar seçilme şansını düşürür. Yani “presence penalty”, bir kelimenin ne kadar sıklıkla kullanıldığını dikkate almaz, sadece metinde \n",
        "# var olup olmadığına bakar. \n",
        "\n",
        "# negatif değerler : “Frequency penalty”, bir kelimenin kullanım sayısı arttıkça o kelimenin tekrar seçilme olasılığını artırır, “presence penalty” bir kelimenin daha \n",
        "# önce kullanılmış olup olmadığına bakarak tekrar seçilme şansını artırır.\n",
        "\n",
        "# “Frequency penalty”, “presence penalty” -2 ile +2 arasında değer alsa da 0.1 ile 1 arasında değerlerin kullanılması tavsiye edilmiştir."
      ],
      "metadata": {
        "id": "sJBduWlkltl7"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8cx-QhwmmprU",
        "outputId": "44585667-1dbd-4b5f-fc73-2c51ad18fbeb"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<OpenAIObject text_completion id=cmpl-7N1aggMqD9Xh36qMPtyBPdunrtt9a at 0x7ff6e24049f0> JSON: {\n",
              "  \"choices\": [\n",
              "    {\n",
              "      \"finish_reason\": \"stop\",\n",
              "      \"index\": 0,\n",
              "      \"logprobs\": null,\n",
              "      \"text\": \" e.name \\nFROM Employee e \\nINNER JOIN Sales_amount sa \\nON e.id = sa.employee_id \\nWHERE sa.date > DATEADD(month, -3, GETDATE()) \\nGROUP BY e.name \\nHAVING SUM(sa.amount) > 10000\"\n",
              "    }\n",
              "  ],\n",
              "  \"created\": 1685722014,\n",
              "  \"id\": \"cmpl-7N1aggMqD9Xh36qMPtyBPdunrtt9a\",\n",
              "  \"model\": \"text-davinci-003\",\n",
              "  \"object\": \"text_completion\",\n",
              "  \"usage\": {\n",
              "    \"completion_tokens\": 72,\n",
              "    \"prompt_tokens\": 79,\n",
              "    \"total_tokens\": 151\n",
              "  }\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response[\"choices\"][0] # choices içerisindeki dictionary'e giriş yapıyoruz."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z0gDqpP3mqi0",
        "outputId": "04d6770b-e611-4780-8314-329309c8da25"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<OpenAIObject at 0x7ff6e175b790> JSON: {\n",
              "  \"finish_reason\": \"stop\",\n",
              "  \"index\": 0,\n",
              "  \"logprobs\": null,\n",
              "  \"text\": \" e.name \\nFROM Employee e \\nINNER JOIN Sales_amount sa \\nON e.id = sa.employee_id \\nWHERE sa.date > DATEADD(month, -3, GETDATE()) \\nGROUP BY e.name \\nHAVING SUM(sa.amount) > 10000\"\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"SELECT\"+response[\"choices\"][0][\"text\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JgR3ZneZmzzY",
        "outputId": "3bf0d28d-dfa8-473a-cf0b-299a959b26e7"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SELECT e.name \n",
            "FROM Employee e \n",
            "INNER JOIN Sales_amount sa \n",
            "ON e.id = sa.employee_id \n",
            "WHERE sa.date > DATEADD(month, -3, GETDATE()) \n",
            "GROUP BY e.name \n",
            "HAVING SUM(sa.amount) > 10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"### Microsoft SQL tables, with their properties:\n",
        "#\n",
        "# Employee(id, name, department_id)\n",
        "# Department(id, name, address)\n",
        "# Sales_amount(id, employee_id, amount, date)\n",
        "#\n",
        "### A query to list the names of employees whose total sales in the last 3 months have been more than 10 thousand EURO\n",
        "SELECT\"\"\""
      ],
      "metadata": {
        "id": "Ox8ZjaEktq37"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = openai.Completion.create(\n",
        "  model=\"text-davinci-003\",\n",
        "  prompt=prompt,\n",
        "  temperature=0,\n",
        "  max_tokens=150,\n",
        "  top_p=1.0,\n",
        "  frequency_penalty=0.0,\n",
        "  presence_penalty=0.0,\n",
        "  stop=[\"###\", \";\"]\n",
        ")\n",
        "print(\"SELECT\"+response[\"choices\"][0][\"text\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cdN3o0SqtrEx",
        "outputId": "712bdbcd-ca9b-44e5-cdb3-f157004dec43"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SELECT e.name \n",
            "FROM Employee e \n",
            "INNER JOIN Sales_amount sa \n",
            "ON e.id = sa.employee_id \n",
            "WHERE sa.date > DATEADD(month, -3, GETDATE()) \n",
            "GROUP BY e.name \n",
            "HAVING SUM(sa.amount) > 10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### With GPT-3.5"
      ],
      "metadata": {
        "id": "uAsW9UTas7WT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "One-Shot Training"
      ],
      "metadata": {
        "id": "X3TaB2gKl3yM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "system=\"\"\"You are a Microsoft SQL expert. Answer the questions asked to you in the most accurate way. Return only the query that was asked to you.\n",
        "Microsoft SQL tables, with their properties:\n",
        "Employee(id, name, department_id)\n",
        "Department(id, name, address)\n",
        "Sales_amount(id, employee_id, amount, date)\"\"\"\n",
        "\n",
        "user1 = \"write a query to list the names of the employees who live in Ankara\"\n",
        "\n",
        "assistant = \"\"\"SELECT Employee.name \n",
        "FROM Employee \n",
        "JOIN Department \n",
        "ON Employee.department_id = Department.id \n",
        "WHERE Department.address = 'Ankara';\"\"\"\n",
        "\n",
        "user2 = \"write a query to list the names of employees whose total sales in the last 3 months have been more than 10 thousand EURO. just return query\""
      ],
      "metadata": {
        "id": "YlAxs7T43Zd4"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "\n",
        "res = openai.ChatCompletion.create(\n",
        "          model=\"gpt-3.5-turbo\",\n",
        "          messages=[\n",
        "          {\"role\": \"system\", \"content\": f\"{system}\"},\n",
        "          {\"role\": \"user\", \"content\": f\"{user1}\"},\n",
        "          {\"role\": \"assistant\", \"content\": f\"{assistant}\"},\n",
        "          {\"role\": \"user\", \"content\": f\"{user2}\"}\n",
        "      ]\n",
        "  )"
      ],
      "metadata": {
        "id": "4-j0WCLu3XIj"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "epr_b10V1I2E",
        "outputId": "4eb852f8-3078-4cf2-d8bd-a41715c44a4a"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<OpenAIObject chat.completion id=chatcmpl-7N1ciOCAHrjEehoaRtoWEJcv4eT1x at 0x7ff6d152e750> JSON: {\n",
              "  \"choices\": [\n",
              "    {\n",
              "      \"finish_reason\": \"stop\",\n",
              "      \"index\": 0,\n",
              "      \"message\": {\n",
              "        \"content\": \"SELECT Employee.name \\nFROM Employee \\nJOIN Sales_amount \\nON Employee.id = Sales_amount.employee_id \\nWHERE Sales_amount.date >= DATEADD(month, -3, GETDATE()) \\nGROUP BY Employee.id, Employee.name \\nHAVING SUM(Sales_amount.amount) > 10000;\",\n",
              "        \"role\": \"assistant\"\n",
              "      }\n",
              "    }\n",
              "  ],\n",
              "  \"created\": 1685722140,\n",
              "  \"id\": \"chatcmpl-7N1ciOCAHrjEehoaRtoWEJcv4eT1x\",\n",
              "  \"model\": \"gpt-3.5-turbo-0301\",\n",
              "  \"object\": \"chat.completion\",\n",
              "  \"usage\": {\n",
              "    \"completion_tokens\": 57,\n",
              "    \"prompt_tokens\": 157,\n",
              "    \"total_tokens\": 214\n",
              "  }\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(res[\"choices\"][0][\"message\"][\"content\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0fYLWK8V2GVQ",
        "outputId": "57993f15-5369-4e9a-8821-eff3b7be16a4"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SELECT Employee.name \n",
            "FROM Employee \n",
            "JOIN Sales_amount \n",
            "ON Employee.id = Sales_amount.employee_id \n",
            "WHERE Sales_amount.date >= DATEADD(month, -3, GETDATE()) \n",
            "GROUP BY Employee.id, Employee.name \n",
            "HAVING SUM(Sales_amount.amount) > 10000;\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def chatgpt(system, question):\n",
        "\n",
        "  import openai\n",
        "\n",
        "  res = openai.ChatCompletion.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    messages=[\n",
        "          {\"role\": \"system\", \"content\": f\"{system}\"},\n",
        "          {\"role\": \"user\", \"content\": f\"{question}\"}],\n",
        "    temperature=0,\n",
        "    top_p=1,\n",
        "    max_tokens=500,\n",
        "    presence_penalty=0,\n",
        "    frequency_penalty=0,\n",
        "\n",
        "    )\n",
        "\n",
        "  return print(res['choices'][0][\"message\"][\"content\"])"
      ],
      "metadata": {
        "id": "b9lVn9ops9ZI"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "system = \"\"\"You are a Microsoft SQL expert. Answer the questions asked to you in the most accurate way. Return only the query that was asked to you.\n",
        "Microsoft SQL tables, with their properties:\n",
        "Employee(id, name, department_id)\n",
        "Department(id, name, address)\n",
        "Sales_amount(id, employee_id, amount, date)\"\"\"\n",
        "\n",
        "question = \"write a query to list the names of employees whose total sales in the last 3 months have been more than 10 thousand EURO. just return query\"\n",
        "\n",
        "chatgpt(system, question)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IPW-XM6w8c0W",
        "outputId": "7e06da60-fdfa-476b-95ba-254e42380d19"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "```\n",
            "SELECT e.name\n",
            "FROM Employee e\n",
            "INNER JOIN Sales_amount sa ON e.id = sa.employee_id\n",
            "WHERE sa.date >= DATEADD(month, -3, GETDATE())\n",
            "GROUP BY e.id, e.name\n",
            "HAVING SUM(sa.amount) > 10000\n",
            "```\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Python to natural language"
      ],
      "metadata": {
        "id": "9iX8HwOmBsbh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt =\"\"\"# Python 3 \n",
        "def remove_common_prefix(x, prefix, ws_prefix): \n",
        "    x[\"completion\"] = x[\"completion\"].str[len(prefix) :] \n",
        "    if ws_prefix: \n",
        "        # keep the single whitespace as prefix \n",
        "        x[\"completion\"] = \" \" + x[\"completion\"] \n",
        "return x \n",
        "\n",
        "# Explanation of what the code does\n",
        "\n",
        "#\"\"\""
      ],
      "metadata": {
        "id": "XHl8-zG8B3IV"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = openai.Completion.create(\n",
        "  model=\"text-davinci-003\",\n",
        "  prompt=prompt,\n",
        "  temperature=0,\n",
        "  max_tokens=500,\n",
        "  top_p=1.0,\n",
        "  frequency_penalty=0.0,\n",
        "  presence_penalty=0.0,\n",
        "  stop=[\"#\"]\n",
        ")\n",
        "print(response[\"choices\"][0][\"text\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3hm1gobQBumb",
        "outputId": "6e939cae-2c5d-4301-ff9d-d756489f45b3"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This code removes a common prefix from a given string. The parameters x, prefix, and ws_prefix are passed into the function. The x parameter is a dataframe containing a column called \"completion\". The prefix parameter is the string that is to be removed from the \"completion\" column. The ws_prefix parameter is a boolean value that determines whether or not a single whitespace should be kept as a prefix. \n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "system = \"You are a python 3 expert. Answer the questions asked to you in the most accurate way.\"\n",
        "\n",
        "question = \"\"\"\n",
        "def remove_common_prefix(x, prefix, ws_prefix): \n",
        "    x[\"completion\"] = x[\"completion\"].str[len(prefix) :] \n",
        "    if ws_prefix: \n",
        "        # keep the single whitespace as prefix \n",
        "        x[\"completion\"] = \" \" + x[\"completion\"] \n",
        "return x\n",
        "Explanation of what the code does\"\"\"\n",
        "\n",
        "chatgpt(system, question)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ejnjHPuCPaf",
        "outputId": "c7ebd2c4-9439-4c19-bde7-2da49a875e4c"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This code defines a function called `remove_common_prefix` that takes three arguments: `x`, `prefix`, and `ws_prefix`. The function removes the common prefix from the \"completion\" column of the input dataframe `x`. \n",
            "\n",
            "First, the function removes the prefix from the \"completion\" column by using the `str` method of pandas dataframe and slicing the string from the length of the prefix to the end of the string. \n",
            "\n",
            "If `ws_prefix` is True, the function adds a single whitespace as the new prefix to the \"completion\" column. \n",
            "\n",
            "Finally, the function returns the modified dataframe `x`.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Translate programming languages"
      ],
      "metadata": {
        "id": "YbLgd1taENty"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"##### Translate this code from R into Python3\n",
        "### R\n",
        "    \n",
        "    set.seed(42)\n",
        "    train_index <- createDataPartition(y, p = 0.9, list = FALSE)\n",
        "    X_train <- X[train_index, ]\n",
        "    X_test <- X[-train_index, ]\n",
        "    y_train <- y[train_index]\n",
        "    y_test <- y[-train_index]\n",
        "    \n",
        "### Python3\"\"\""
      ],
      "metadata": {
        "id": "-xz_XhhFE49J"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "\n",
        "response = openai.Completion.create(\n",
        "  model=\"text-davinci-003\",\n",
        "  prompt=prompt,\n",
        "  temperature=0,\n",
        "  max_tokens=150,\n",
        "  top_p=1.0,\n",
        "  frequency_penalty=0.0,\n",
        "  presence_penalty=0.0,\n",
        "  stop=[\"###\"]\n",
        ")\n",
        "print(response[\"choices\"][0][\"text\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kn4LI64-EPh4",
        "outputId": "147e4b87-fbed-4f99-a665-3ba769ef3de1"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "    np.random.seed(42)\n",
            "    train_index = np.random.choice(len(y), round(0.9*len(y)), replace=False)\n",
            "    X_train = X[train_index]\n",
            "    X_test = X[~train_index]\n",
            "    y_train = y[train_index]\n",
            "    y_test = y[~train_index]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "system = \"You are a python3 and R expert. Answer the questions asked to you in the most accurate way.\"\n",
        "\n",
        "question = \"\"\"\n",
        "set.seed(42)\n",
        "train_index <- createDataPartition(y, p = 0.9, list = FALSE)\n",
        "X_train <- X[train_index, ]\n",
        "X_test <- X[-train_index, ]\n",
        "y_train <- y[train_index]\n",
        "y_test <- y[-train_index]\n",
        "Translate this code from R into Python3\"\"\"\n",
        "\n",
        "chatgpt(system, question)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LBKkT4pBFJft",
        "outputId": "1813a56b-9f1f-447a-d71a-91ad377d2bd7"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "import numpy as np\n",
            "from sklearn.model_selection import train_test_split\n",
            "\n",
            "np.random.seed(42)\n",
            "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Explain Code"
      ],
      "metadata": {
        "id": "_f2Su2duJwI4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt= \"\"\"\n",
        "class Log:\n",
        "    def __init__(self, path):\n",
        "        dirname = os.path.dirname(path)\n",
        "        os.makedirs(dirname, exist_ok=True)\n",
        "        f = open(path, \"a+\")\n",
        "\n",
        "        # Check that the file is newline-terminated\n",
        "        size = os.path.getsize(path)\n",
        "        if size > 0:\n",
        "            f.seek(size - 1)\n",
        "            end = f.read(1)\n",
        "            if end != \"\\n\":\n",
        "                f.write(\"\\n\")\n",
        "        self.f = f\n",
        "        self.path = path\n",
        "\n",
        "    def log(self, event):\n",
        "        event[\"_event_id\"] = str(uuid.uuid4())\n",
        "        json.dump(event, self.f)\n",
        "        self.f.write(\"\\n\")\n",
        "\n",
        "    def state(self):\n",
        "        state = {\"complete\": set(), \"last\": None}\n",
        "        for line in open(self.path):\n",
        "            event = json.loads(line)\n",
        "            if event[\"type\"] == \"submit\" and event[\"success\"]:\n",
        "                state[\"complete\"].add(event[\"id\"])\n",
        "                state[\"last\"] = event\n",
        "        return state\n",
        "\n",
        "\\\"\\\"\\\"\n",
        "Here's what the above class is doing, explained in a concise way:\n",
        "1.\"\"\""
      ],
      "metadata": {
        "id": "HdEhvfVEJulg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "\n",
        "response = openai.Completion.create(\n",
        "  model=\"text-davinci-003\",\n",
        "  prompt=prompt,\n",
        "  temperature=0,\n",
        "  max_tokens=300,\n",
        "  top_p=1.0,\n",
        "  frequency_penalty=0.0,\n",
        "  presence_penalty=0.0,\n",
        "  stop=[\"\\\"\\\"\\\"\"]\n",
        ")\n",
        "print(\"1.\"+response[\"choices\"][0][\"text\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gui9qXQyJus6",
        "outputId": "2f420320-a908-4f2b-f7e4-963cc2699720"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1. The __init__ method creates a new file at the given path, and checks that it is newline-terminated.\n",
            "2. The log method adds a new event to the log file, with a unique ID.\n",
            "3. The state method reads the log file and returns a dictionary containing the set of completed tasks and the last successful event.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "system = \"You are a python3 expert. explain the python codes asked to you in the most accurate way.\"\n",
        "\n",
        "question = \"\"\"\n",
        "class Log:\n",
        "    def __init__(self, path):\n",
        "        dirname = os.path.dirname(path)\n",
        "        os.makedirs(dirname, exist_ok=True)\n",
        "        f = open(path, \"a+\")\n",
        "\n",
        "        # Check that the file is newline-terminated\n",
        "        size = os.path.getsize(path)\n",
        "        if size > 0:\n",
        "            f.seek(size - 1)\n",
        "            end = f.read(1)\n",
        "            if end != \"\\n\":\n",
        "                f.write(\"\\n\")\n",
        "        self.f = f\n",
        "        self.path = path\n",
        "\n",
        "    def log(self, event):\n",
        "        event[\"_event_id\"] = str(uuid.uuid4())\n",
        "        json.dump(event, self.f)\n",
        "        self.f.write(\"\\n\")\n",
        "\n",
        "    def state(self):\n",
        "        state = {\"complete\": set(), \"last\": None}\n",
        "        for line in open(self.path):\n",
        "            event = json.loads(line)\n",
        "            if event[\"type\"] == \"submit\" and event[\"success\"]:\n",
        "                state[\"complete\"].add(event[\"id\"])\n",
        "                state[\"last\"] = event\n",
        "        return state\n",
        "explain, point by point, what the above class does\"\"\"\n",
        "\n",
        "chatgpt(system, question)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CChWc6iEKSgZ",
        "outputId": "84312e94-91c6-4b10-a737-0908d061d0c5"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The above code defines a class called `Log`. Here is what it does:\n",
            "\n",
            "1. The `__init__` method takes a `path` argument and creates a file object at that path. If the directory of the path does not exist, it creates it. It also checks if the file is newline-terminated and adds a newline character if it is not.\n",
            "\n",
            "2. The `log` method takes an `event` argument, adds a unique `_event_id` key to the event dictionary using the `uuid.uuid4()` method, and writes the event dictionary to the file object in JSON format. It also adds a newline character after writing the event.\n",
            "\n",
            "3. The `state` method reads the file object line by line, loads each line as a JSON object, and checks if the object has a `\"type\"` key with the value `\"submit\"` and a `\"success\"` key with the value `True`. If it does, it adds the `\"id\"` key to a set called `\"complete\"` and sets the `\"last\"` key to the current event. Finally, it returns a dictionary with the `\"complete\"` set and the `\"last\"` event.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Python bug fixer"
      ],
      "metadata": {
        "id": "KwPXWuXdLNWN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt =\"\"\"\n",
        "##### Fix bugs in the below function\n",
        " \n",
        "### Buggy Python\n",
        "import Random\n",
        "a = random.randint(1,12)\n",
        "b = random.randint(1,12)\n",
        "for i in range(10):\n",
        "    question = \"What is \"+a+\" x \"+b+\"? \"\n",
        "    answer = input(question)\n",
        "    if answer = a*b\n",
        "        print (Well done!)\n",
        "    else:\n",
        "        print(\"No.\")\n",
        "    \n",
        "### Fixed Python\"\"\""
      ],
      "metadata": {
        "id": "Qu7Bnm7lLSFp"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "\n",
        "response = openai.Completion.create(\n",
        "  model=\"text-davinci-003\",\n",
        "  prompt=prompt,\n",
        "  temperature=0,\n",
        "  max_tokens=300,\n",
        "  top_p=1.0,\n",
        "  frequency_penalty=0.0,\n",
        "  presence_penalty=0.0,\n",
        "  stop=[\"###\"]\n",
        ")\n",
        "print(response[\"choices\"][0][\"text\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D-_qgVCgLq90",
        "outputId": "e10b86b7-ebc8-4124-b96c-97356db285b2"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "import random\n",
            "a = random.randint(1,12)\n",
            "b = random.randint(1,12)\n",
            "for i in range(10):\n",
            "    question = \"What is \"+str(a)+\" x \"+str(b)+\"? \"\n",
            "    answer = int(input(question))\n",
            "    if answer == a*b:\n",
            "        print (\"Well done!\")\n",
            "    else:\n",
            "        print(\"No.\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "system = \"You are a python3 expert. fix bugs in the python codes asked to you in the most accurate way.\"\n",
        "\n",
        "question = \"\"\"\n",
        "import Random\n",
        "a = random.randint(1,12)\n",
        "b = random.randint(1,12)\n",
        "for i in range(10):\n",
        "    question = \"What is \"+a+\" x \"+b+\"? \"\n",
        "    answer = input(question)\n",
        "    if answer = a*b\n",
        "        print (Well done!)\n",
        "    else:\n",
        "        print(\"No.\")\"\"\"\n",
        "\n",
        "chatgpt(system, question)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OW2hy_wvL5x-",
        "outputId": "70f0b6a4-02af-49a9-c608-62c17a9eb85f"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are several errors in the code. Here's the corrected code:\n",
            "\n",
            "```python\n",
            "import random\n",
            "\n",
            "a = random.randint(1, 12)\n",
            "b = random.randint(1, 12)\n",
            "\n",
            "for i in range(10):\n",
            "    question = \"What is \" + str(a) + \" x \" + str(b) + \"? \"\n",
            "    answer = int(input(question))\n",
            "    if answer == a * b:\n",
            "        print(\"Well done!\")\n",
            "    else:\n",
            "        print(\"No.\")\n",
            "```\n",
            "\n",
            "Changes made:\n",
            "- `random` module was imported with a capital R, which is incorrect. It should be `import random`.\n",
            "- The variables `a` and `b` were not converted to strings before concatenating with other strings. I added `str()` to convert them to strings.\n",
            "- The `input()` function returns a string, so the `answer` variable needs to be converted to an integer using `int()`.\n",
            "- The `if` statement had a syntax error. The comparison operator `==` was used instead of `=`. Also, the string \"Well done!\" was not enclosed in quotes.\n",
            "- The `else` statement was missing quotes around the string \"No.\".\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "system = \"You are a python3 expert. fix bugs in the python codes asked to you in the most accurate way. just return fixed python codes\"\n",
        "\n",
        "question = \"\"\"\n",
        "import Random\n",
        "a = random.randint(1,12)\n",
        "b = random.randint(1,12)\n",
        "for i in range(10):\n",
        "    question = \"What is \"+a+\" x \"+b+\"? \"\n",
        "    answer = input(question)\n",
        "    if answer = a*b\n",
        "        print (Well done!)\n",
        "    else:\n",
        "        print(\"No.\")\"\"\"\n",
        "\n",
        "chatgpt(system, question)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IoW38kA6Mhht",
        "outputId": "8dbfe7a5-1b34-4d1a-f022-ddf2a050288d"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "import random\n",
            "a = random.randint(1,12)\n",
            "b = random.randint(1,12)\n",
            "for i in range(10):\n",
            "    question = \"What is \"+str(a)+\" x \"+str(b)+\"? \"\n",
            "    answer = int(input(question))\n",
            "    if answer == a*b:\n",
            "        print (\"Well done!\")\n",
            "    else:\n",
            "        print(\"No.\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## JavaScript to Python"
      ],
      "metadata": {
        "id": "zMPzq6wUO_yX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt=\"\"\"\n",
        "#JavaScript to Python:\n",
        "JavaScript: \n",
        "dogs = [\"bill\", \"joe\", \"carl\"]\n",
        "car = []\n",
        "dogs.forEach((dog) {\n",
        "    car.push(dog);\n",
        "});\n",
        "\n",
        "Python:\"\"\""
      ],
      "metadata": {
        "id": "JrZbsNwhPBfc"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "\n",
        "response = openai.Completion.create(\n",
        "  model=\"text-davinci-003\",\n",
        "  prompt=prompt,\n",
        "  temperature=0,\n",
        "  max_tokens=300,\n",
        "  top_p=1.0,\n",
        "  frequency_penalty=0.0,\n",
        "  presence_penalty=0.0\n",
        ")\n",
        "print(response[\"choices\"][0][\"text\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "onYk524ZPLVj",
        "outputId": "67363476-6b41-40c3-c74f-caac12c54785"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "dogs = [\"bill\", \"joe\", \"carl\"]\n",
            "car = []\n",
            "for dog in dogs:\n",
            "    car.append(dog)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "system = \"You are a python3 and javascript expert. Translate this code from javascript into Python3 in the most accurate way.\"\n",
        "\n",
        "question = \"\"\"\n",
        "dogs = [\"bill\", \"joe\", \"carl\"]\n",
        "car = []\n",
        "dogs.forEach((dog) {\n",
        "    car.push(dog);\n",
        "});\"\"\"\n",
        "\n",
        "chatgpt(system, question)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "voq7UeqDPTgv",
        "outputId": "869f2834-21a8-4fca-f2de-a205d3d56163"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dogs = [\"bill\", \"joe\", \"carl\"]\n",
            "car = []\n",
            "for dog in dogs:\n",
            "    car.append(dog)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Write a Python docstring"
      ],
      "metadata": {
        "id": "z9uPvluDQaNp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt=\"\"\"\n",
        "# Python 3 \n",
        "def remove_common_prefix(x, prefix, ws_prefix): \n",
        "    x[\"completion\"] = x[\"completion\"].str[len(prefix) :] \n",
        "    if ws_prefix: \n",
        "        # keep the single whitespace as prefix \n",
        "        x[\"completion\"] = \" \" + x[\"completion\"] \n",
        "return x \n",
        "\n",
        "# An elaborate, high quality docstring for the above function:\n",
        "\\\"\\\"\\\"\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "emIPUzTcQbi7"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "mGDEDNL26uvQ",
        "outputId": "e4f88b41-b900-4efe-e750-371ae2ce3795"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n# Python 3 \\ndef remove_common_prefix(x, prefix, ws_prefix): \\n    x[\"completion\"] = x[\"completion\"].str[len(prefix) :] \\n    if ws_prefix: \\n        # keep the single whitespace as prefix \\n        x[\"completion\"] = \" \" + x[\"completion\"] \\nreturn x \\n\\n# An elaborate, high quality docstring for the above function:\\n\"\"\"\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "\n",
        "response = openai.Completion.create(\n",
        "  model=\"text-davinci-003\",\n",
        "  prompt=prompt,\n",
        "  temperature=0,\n",
        "  max_tokens=150,\n",
        "  top_p=1.0,\n",
        "  frequency_penalty=0.0,\n",
        "  presence_penalty=0.0,\n",
        "  stop=[\"#\", \"\\\"\\\"\\\"\"]\n",
        ")\n",
        "print(response[\"choices\"][0][\"text\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Yb0MJ7nRSFq",
        "outputId": "15297ef1-aec7-4e56-d166-ec2c0601c1da"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "remove_common_prefix(x, prefix, ws_prefix)\n",
            "\n",
            "This function removes a common prefix from a given string.\n",
            "\n",
            "Parameters:\n",
            "    x (str): The string to remove the prefix from.\n",
            "    prefix (str): The prefix to remove from the string.\n",
            "    ws_prefix (bool): Whether to keep a single whitespace as the prefix.\n",
            "\n",
            "Returns:\n",
            "    x (str): The string with the prefix removed.\n",
            "\n",
            "Raises:\n",
            "    ValueError: If the prefix is not found in the string.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "system = \"You are a python3 expert. write high quality docstring for Python3 codes given to you the most accurate way.\"\n",
        "\n",
        "question = \"\"\"\n",
        "def remove_common_prefix(x, prefix, ws_prefix): \n",
        "    x[\"completion\"] = x[\"completion\"].str[len(prefix) :] \n",
        "    if ws_prefix: \n",
        "        # keep the single whitespace as prefix \n",
        "        x[\"completion\"] = \" \" + x[\"completion\"] \n",
        "return x \"\"\"\n",
        "\n",
        "chatgpt(system, question)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H1ldkHllRfsz",
        "outputId": "62c9f2d1-b5f4-44e9-95b8-3551b9ff3458"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\"\"\"\n",
            "Removes a common prefix from a given string in a pandas DataFrame column.\n",
            "\n",
            "Args:\n",
            "    x (pandas.DataFrame): A pandas DataFrame containing a column named \"completion\" that needs to be modified.\n",
            "    prefix (str): The common prefix to be removed from the \"completion\" column.\n",
            "    ws_prefix (bool): A boolean value indicating whether to keep a single whitespace as prefix after removing the common prefix.\n",
            "\n",
            "Returns:\n",
            "    pandas.DataFrame: The modified pandas DataFrame with the common prefix removed from the \"completion\" column.\n",
            "\n",
            "Example:\n",
            "    >>> df = pd.DataFrame({'completion': ['apple', 'apples', 'apricot']})\n",
            "    >>> df = remove_common_prefix(df, 'ap', True)\n",
            "    >>> print(df)\n",
            "         completion\n",
            "    0       ple\n",
            "    1      ples\n",
            "    2     ricot\n",
            "\"\"\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Edit Codes"
      ],
      "metadata": {
        "id": "Kbk_PD6MTBzP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def CodeEdit(input, instruction):\n",
        "\n",
        "  import openai\n",
        "\n",
        "  res = openai.Edit.create(\n",
        "    model= \"code-davinci-edit-001\",\n",
        "    input= f\"{input}\",\n",
        "    instruction= f\"{instruction}\",\n",
        "    temperature=0.0,\n",
        "    top_p=1)\n",
        "  return print(res[\"choices\"][0][\"text\"])"
      ],
      "metadata": {
        "id": "lazXgBoUTEd2"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CodeEdit(input=\" \", instruction=\"Write a function in python that calculates fibonacci\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8T7_3Wo9TNvY",
        "outputId": "b8c99db3-db44-478d-8c2e-627d35f5c7cb"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "def fibonacci(n):\n",
            "    if n == 0:\n",
            "        return 0\n",
            "    elif n == 1:\n",
            "        return 1\n",
            "    else:\n",
            "        return fibonacci(n-1) + fibonacci(n-2)\n",
            "\n",
            "print(fibonacci(9))\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input = \"\"\"def fibonacci(n):\n",
        "    if n == 0:\n",
        "        return 0\n",
        "    elif n == 1:\n",
        "        return 1\n",
        "    else:\n",
        "        return fibonacci(n-1) + fibonacci(n-2)\n",
        "\n",
        "print(fibonacci(9))\"\"\"\n",
        "CodeEdit(input=input, instruction=\"Add docstring\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WbsF83t8TQxj",
        "outputId": "88ddf311-248e-40da-eff4-c5bf3e6812cf"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "def fibonacci(n):\n",
            "    \"\"\"\n",
            "    Returns the nth number in the fibonacci sequence\n",
            "    \"\"\"\n",
            "    if n == 0:\n",
            "        return 0\n",
            "    elif n == 1:\n",
            "        return 1\n",
            "    else:\n",
            "        return fibonacci(n-1) + fibonacci(n-2)\n",
            "\n",
            "print(fibonacci(9))\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input = \"\"\"def fibonacci(n):\n",
        "    \\\"\\\"\\\"\n",
        "    Returns the nth number in the fibonacci sequence\n",
        "    \\\"\\\"\\\"\n",
        "    if n == 0:\n",
        "        return 0\n",
        "    elif n == 1:\n",
        "        return 1\n",
        "    else:\n",
        "        return fibonacci(n-1) + fibonacci(n-2)\n",
        "\n",
        "print(fibonacci(9))\"\"\"\n",
        "CodeEdit(input=input, instruction=\"Rename the function to fib\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nqrizhh0Tdt3",
        "outputId": "55b82661-de22-404f-ef78-e385c67b7336"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "def fib(n):\n",
            "    \"\"\"\n",
            "    Returns the nth number in the fibonacci sequence\n",
            "    \"\"\"\n",
            "    if n == 0:\n",
            "        return 0\n",
            "    elif n == 1:\n",
            "        return 1\n",
            "    else:\n",
            "        return fib(n-1) + fib(n-2)\n",
            "\n",
            "print(fib(9))\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "instruction=\"1 ile 100 arasındaki 3 ve 5'e bölünen sayıları bulan python3 kodunu yaz\"\n",
        "CodeEdit(input=\" \", instruction=instruction)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R1IF6nE1ToUm",
        "outputId": "0fe492e5-b087-4928-c2d0-d14b14fab468"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for i in range(1,101):\n",
            "    if i%3==0 and i%5==0:\n",
            "        print(i)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "instruction=\"\"\"Microsoft SQL tabloları:\n",
        "\n",
        "Employee(id, name, department_id)\n",
        "Department(id, name, address)\n",
        "Sales_amount(id, employee_id, amount, date)\n",
        "\n",
        "yukarıdaki tablolara göre son 5 ay içerisinde toplam olarak 10 bin tl satış yapan çalışanların isimlerini listeyen query'i yaz\"\"\"\n",
        "CodeEdit(input=\" \", instruction=instruction)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3wbaf_CEUD3L",
        "outputId": "a39dc189-357a-4424-bdc2-4dbf9bb74f82"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SELECT e.name\n",
            "FROM Employee e\n",
            "INNER JOIN Sales_amount s ON e.id = s.employee_id\n",
            "WHERE s.date BETWEEN DATEADD(MONTH, -5, GETDATE()) AND GETDATE()\n",
            "GROUP BY e.name\n",
            "HAVING SUM(s.amount) >= 10000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input=\"\"\"dogs = [\"bill\", \"joe\", \"carl\"]\n",
        "car = []\n",
        "dogs.forEach((dog) {\n",
        "    car.push(dog);\n",
        "});\"\"\"\n",
        "\n",
        "instruction= \"python'a dönüştür\"\n",
        "\n",
        "CodeEdit(input=input, instruction=instruction)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QMjE2SBmUzcu",
        "outputId": "e34c6150-8f02-45f5-95fb-17e93d51330c"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dogs = [\"bill\", \"joe\", \"carl\"];\n",
            "car = [];\n",
            "for dog in dogs:\n",
            "    car.append(dog);\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input = \"\"\"\n",
        "set.seed(42)\n",
        "train_index <- createDataPartition(y, p = 0.9, list = FALSE)\n",
        "X_train <- X[train_index, ]\n",
        "X_test <- X[-train_index, ]\n",
        "y_train <- y[train_index]\n",
        "y_test <- y[-train_index]\"\"\"\n",
        "\n",
        "instruction= \"R'dan python'a dönüştür.\"\n",
        "\n",
        "CodeEdit(input=input, instruction=instruction)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K7qxhOCNa0Pb",
        "outputId": "629833f2-03bb-45d3-b26f-725a57105fda"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "import pandas as pd\n",
            "import numpy as np\n",
            "from sklearn.model_selection import train_test_split\n",
            "\n",
            "df = pd.read_csv(\"data.csv\")\n",
            "\n",
            "X = df.drop([\"y\"], axis=1)\n",
            "y = df[\"y\"]\n",
            "\n",
            "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#"
      ],
      "metadata": {
        "id": "wcFUc14ex8rL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Count of tokens for gpt-3.5-turbo-0301"
      ],
      "metadata": {
        "id": "IOsuQXQLx90U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tiktoken"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eRr_XkQ9cVPH",
        "outputId": "582cc16c-8f37-4f5d-b266-f0cecef812c7"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tiktoken\n",
            "  Downloading tiktoken-0.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m54.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2022.10.31)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.27.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.4)\n",
            "Installing collected packages: tiktoken\n",
            "Successfully installed tiktoken-0.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def num_tokens_from_messages(messages, model=\"gpt-3.5-turbo-0301\"):\n",
        "  \"\"\"Returns the number of tokens used by a list of messages.\"\"\"\n",
        "  import tiktoken\n",
        "  try:\n",
        "      encoding = tiktoken.encoding_for_model(model)\n",
        "  except KeyError:\n",
        "      encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
        "  if model == \"gpt-3.5-turbo-0301\":  # note: future models may deviate from this\n",
        "      num_tokens = 0\n",
        "      for message in messages:\n",
        "          num_tokens += 4  # every message follows <im_start>{role/name}\\n{content}<im_end>\\n\n",
        "          for key, value in message.items():\n",
        "              num_tokens += len(encoding.encode(value))\n",
        "              if key == \"name\":  # if there's a name, the role is omitted\n",
        "                  num_tokens += -1  # role is always required and always 1 token\n",
        "      num_tokens += 2  # every reply is primed with <im_start>assistant\n",
        "      return num_tokens\n",
        "  else:\n",
        "      raise NotImplementedError(f\"\"\"num_tokens_from_messages() is not presently implemented for model {model}.\n",
        "  See https://github.com/openai/openai-python/blob/main/chatml.md for information on how messages are converted to tokens.\"\"\")"
      ],
      "metadata": {
        "id": "SUlq_cqRx7MN"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "messages = [\n",
        "  {\"role\": \"system\", \"content\": \"You are a helpful, pattern-following assistant that translates corporate jargon into plain English.\"},\n",
        "  {\"role\": \"system\", \"name\":\"example_user\", \"content\": \"New synergies will help drive top-line growth.\"},\n",
        "  {\"role\": \"system\", \"name\": \"example_assistant\", \"content\": \"Things working well together will increase revenue.\"},\n",
        "  {\"role\": \"system\", \"name\":\"example_user\", \"content\": \"Let's circle back when we have more bandwidth to touch base on opportunities for increased leverage.\"},\n",
        "  {\"role\": \"system\", \"name\": \"example_assistant\", \"content\": \"Let's talk later when we're less busy about how to do better.\"},\n",
        "  {\"role\": \"user\", \"content\": \"This late pivot means we don't have time to boil the ocean for the client deliverable.\"},\n",
        "]\n",
        "\n",
        "model = \"gpt-3.5-turbo-0301\"\n",
        "\n",
        "print(f\"{num_tokens_from_messages(messages, model)} prompt tokens counted.\")\n",
        "# Should show ~126 total_tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d227bf8f-4a96-4d49-cbb9-65738473e9eb",
        "id": "iDQMWSZ-x7MO"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "126 prompt tokens counted.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SgfDH9FlxxGJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}